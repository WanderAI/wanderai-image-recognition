{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql5O746UAzoD"
      },
      "source": [
        "# Mulai"
      ],
      "id": "Ql5O746UAzoD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMF-jyuYAzcU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import Model\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "hMF-jyuYAzcU"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDDfzeC4Bvm7",
        "outputId": "a4974bca-a15f-466a-c5f7-80dee0a4955a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "id": "KDDfzeC4Bvm7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEVUHYASCt2b"
      },
      "outputs": [],
      "source": [
        "source_path = \"/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML\""
      ],
      "id": "oEVUHYASCt2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKC9cBPPC0pZ",
        "outputId": "9e0e4c06-7a80-4233-b792-e71ae2699901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 345 images of Monas.\n",
            "There are 283 images of GWK.\n",
            "There are 296 images of Jembatan Ampera.\n",
            "There are 341 images of Jam Gadang.\n",
            "There are 185 images of Kota Tua.\n",
            "There are 283 images of Pura Ulun Danu.\n"
          ]
        }
      ],
      "source": [
        "source_path_monas = os.path.join(source_path, 'monumen nasional jakarta_converted_png')\n",
        "source_path_gwk = os.path.join(source_path, 'garuda wisnu kencana_converted_png')\n",
        "source_path_ampera = os.path.join(source_path, 'jembatan ampera_converted_png')\n",
        "source_path_gadang = os.path.join(source_path, \"jam_gadang_converted_png\")\n",
        "source_path_kotatua = os.path.join(source_path, 'museum_sejarah_converted_png')\n",
        "source_path_ulundanu = os.path.join(source_path, 'ulun danu bratan temple_converted_png')\n",
        "\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_monas))} images of Monas.\")\n",
        "print(f\"There are {len(os.listdir(source_path_gwk))} images of GWK.\")\n",
        "print(f\"There are {len(os.listdir(source_path_ampera))} images of Jembatan Ampera.\")\n",
        "print(f\"There are {len(os.listdir(source_path_gadang))} images of Jam Gadang.\")\n",
        "print(f\"There are {len(os.listdir(source_path_kotatua))} images of Kota Tua.\")\n",
        "print(f\"There are {len(os.listdir(source_path_ulundanu))} images of Pura Ulun Danu.\")\n",
        "\n"
      ],
      "id": "zKC9cBPPC0pZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbBIEQvnJNYT"
      },
      "outputs": [],
      "source": [
        "labels = [\"monas\", \"gwk\", \"ampera\", \"gadang\", \"kotatua\", \"ulundanu\"]\n",
        "ROOT_PATH = \"/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING\"\n",
        "\n",
        "if os.path.exists(ROOT_PATH):\n",
        "  shutil.rmtree(ROOT_PATH)\n",
        "\n",
        "# Create new dirs\n",
        "try:\n",
        "  TRAINING_DIR = os.path.join(ROOT_PATH,'training')\n",
        "  VALIDATION_DIR = os.path.join(ROOT_PATH,'validation')\n",
        "  os.makedirs(ROOT_PATH)\n",
        "  os.makedirs(os.path.join(ROOT_PATH, \"training\"))\n",
        "  os.makedirs(os.path.join(ROOT_PATH, \"validation\"))\n",
        "  for label in labels:\n",
        "    os.makedirs(os.path.join(TRAINING_DIR, label))\n",
        "    os.makedirs(os.path.join(VALIDATION_DIR, label))\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ],
      "id": "fbBIEQvnJNYT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTuMpuzmFrVs",
        "outputId": "4b1905a6-fa6c-4385-e154-7eb3cc60ca7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/training\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/validation\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/training/monas\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/training/gwk\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/training/ampera\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/training/gadang\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/training/kotatua\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/training/ulundanu\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/validation/monas\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/validation/gwk\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/validation/ampera\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/validation/gadang\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/validation/kotatua\n",
            "/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/_MODELLING/validation/ulundanu\n"
          ]
        }
      ],
      "source": [
        "for rootdir, dirs, files in os.walk(ROOT_PATH):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "id": "lTuMpuzmFrVs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_VyxwY-F7LA"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: split_data\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "  \"\"\"\n",
        "  Splits the data into train and test sets\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    TRAINING_DIR (string): directory path to be used for training\n",
        "    VALIDATION_DIR (string): directory path to be used for validation\n",
        "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "  source_path = os.listdir(SOURCE_DIR)\n",
        "\n",
        "  # Shuflles the list\n",
        "  sampling = random.sample(source_path,len(source_path))\n",
        "\n",
        "  split_point_training = int(len(sampling)*SPLIT_SIZE)\n",
        "\n",
        "\n",
        "  for index in range(len(sampling)):\n",
        "    # if item is zero\n",
        "    if os.path.getsize(os.path.join(SOURCE_DIR,source_path[index])) == 0 :\n",
        "      print(f\"{source_path[index]} is zero length, so ignoring\")\n",
        "    # if not zero  \n",
        "    else:\n",
        "      # If part of train\n",
        "      if (index < split_point_training):\n",
        "        copyfile( os.path.join(SOURCE_DIR, source_path[index]), os.path.join(TRAINING_DIR, source_path[index]))\n",
        "      # if part of test\n",
        "      if (index >= split_point_training):\n",
        "        copyfile( os.path.join(SOURCE_DIR, source_path[index]), os.path.join(VALIDATION_DIR, source_path[index]))\n",
        "  ### END CODE HERE"
      ],
      "id": "b_VyxwY-F7LA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ei4hL7TGK9Q"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your split_data function\n",
        "\n",
        "TRAINING_DIR = os.path.join(ROOT_PATH,'training')\n",
        "VALIDATION_DIR = os.path.join(ROOT_PATH,'validation')\n",
        "\n",
        "TRAINING_MONAS_DIR = os.path.join(TRAINING_DIR, \"monas\")\n",
        "VALIDATION_MONAS_DIR = os.path.join(VALIDATION_DIR, \"monas\")\n",
        "\n",
        "TRAINING_GWK_DIR = os.path.join(TRAINING_DIR, \"gwk\")\n",
        "VALIDATION_GWK_DIR = os.path.join(VALIDATION_DIR, \"gwk\")\n",
        "\n",
        "TRAINING_AMPERA_DIR = os.path.join(TRAINING_DIR, \"ampera\")\n",
        "VALIDATION_AMPERA_DIR = os.path.join(VALIDATION_DIR, \"ampera\")\n",
        "\n",
        "TRAINING_GADANG_DIR = os.path.join(TRAINING_DIR, \"gadang\")\n",
        "VALIDATION_GADANG_DIR = os.path.join(VALIDATION_DIR, \"gadang\")\n",
        "\n",
        "TRAINING_KOTATUA_DIR = os.path.join(TRAINING_DIR, \"kotatua\")\n",
        "VALIDATION_KOTATUA_DIR = os.path.join(VALIDATION_DIR, \"kotatua\")\n",
        "\n",
        "TRAINING_ULUNDANU_DIR = os.path.join(TRAINING_DIR, \"ulundanu\")\n",
        "VALIDATION_ULUNDANU_DIR = os.path.join(VALIDATION_DIR, \"ulundanu\")\n",
        "\n",
        "LABEL_DIRS = [\n",
        "  TRAINING_MONAS_DIR,\n",
        "  VALIDATION_MONAS_DIR,\n",
        "  TRAINING_GWK_DIR,\n",
        "  VALIDATION_GWK_DIR,\n",
        "  TRAINING_AMPERA_DIR,\n",
        "  VALIDATION_AMPERA_DIR,\n",
        "  TRAINING_GADANG_DIR,\n",
        "  VALIDATION_GADANG_DIR,\n",
        "  TRAINING_KOTATUA_DIR,\n",
        "  VALIDATION_KOTATUA_DIR,\n",
        "  TRAINING_ULUNDANU_DIR,\n",
        "  VALIDATION_ULUNDANU_DIR,\n",
        "]\n",
        "\n",
        "for dir in LABEL_DIRS:\n",
        "  if len(os.listdir(dir)) > 0:\n",
        "    for file in os.scandir(dir):\n",
        "      os.remove(file.path)\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "\n",
        "# for rootdir, dirs, files in os.walk(ROOT_PATH):\n",
        "#   for subdir in dirs:\n",
        "#     dir = os.path.join(rootdir, subdir)\n",
        "#     if len(os.listdir(dir)) > 0:\n",
        "#       for file in os.scandir(dir):\n",
        "#         if os.path.isfile(file):\n",
        "#           os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .9\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(source_path_monas, TRAINING_MONAS_DIR, VALIDATION_MONAS_DIR, split_size)\n",
        "split_data(source_path_gwk, TRAINING_GWK_DIR, VALIDATION_GWK_DIR, split_size)\n",
        "split_data(source_path_gadang, TRAINING_GADANG_DIR, VALIDATION_GADANG_DIR, split_size)\n",
        "split_data(source_path_kotatua, TRAINING_KOTATUA_DIR, VALIDATION_KOTATUA_DIR, split_size)\n",
        "split_data(source_path_ampera, TRAINING_AMPERA_DIR, VALIDATION_AMPERA_DIR, split_size)\n",
        "split_data(source_path_ulundanu, TRAINING_ULUNDANU_DIR, VALIDATION_ULUNDANU_DIR, split_size)\n"
      ],
      "id": "_ei4hL7TGK9Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2C3ZB-yUItM",
        "outputId": "21a79b0e-6328-4b0c-8008-dfb799ba178a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original monas's directory has 345 images\n",
            "Original gwk's directory has 283 images\n",
            "Original gadang's directory has 341 images\n",
            "Original kotatua's directory has 185 images\n",
            "Original ampera's directory has 296 images\n",
            "Original ulundanu's directory has 283 images\n",
            "\n",
            "\n",
            "There are 310 images of monas for training\n",
            "There are 254 images of gwk for training\n",
            "There are 306 images of gadang for training\n",
            "There are 166 images of kotatua for training\n",
            "There are 266 images of ampera for training\n",
            "There are 254 images of ulundanu for training\n",
            "There are 35 images of monas for validation\n",
            "There are 29 images of gwk for validation\n",
            "There are 35 images of gadang for validation\n",
            "There are 19 images of kotatua for validation\n",
            "There are 30 images of ampera for validation\n",
            "There are 29 images of ulundanu for validation\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
        "print(f\"Original monas's directory has {len(os.listdir(source_path_monas))} images\")\n",
        "print(f\"Original gwk's directory has {len(os.listdir(source_path_gwk))} images\")\n",
        "print(f\"Original gadang's directory has {len(os.listdir(source_path_gadang))} images\")\n",
        "print(f\"Original kotatua's directory has {len(os.listdir(source_path_kotatua))} images\")\n",
        "print(f\"Original ampera's directory has {len(os.listdir(source_path_ampera))} images\")\n",
        "print(f\"Original ulundanu's directory has {len(os.listdir(source_path_ulundanu))} images\\n\\n\")\n",
        "\n",
        "# Training and validation splits. Check that the number of images matches the expected output.\n",
        "print(f\"There are {len(os.listdir(TRAINING_MONAS_DIR))} images of monas for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_GWK_DIR))} images of gwk for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_GADANG_DIR))} images of gadang for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_KOTATUA_DIR))} images of kotatua for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_AMPERA_DIR))} images of ampera for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_ULUNDANU_DIR))} images of ulundanu for training\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_MONAS_DIR))} images of monas for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_GWK_DIR))} images of gwk for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_GADANG_DIR))} images of gadang for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_KOTATUA_DIR))} images of kotatua for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_AMPERA_DIR))} images of ampera for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_ULUNDANU_DIR))} images of ulundanu for validation\")"
      ],
      "id": "m2C3ZB-yUItM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFNk0wU8UkMB"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "  \n",
        "  Args:\n",
        "    TRAINING_DIR (string): directory path containing the training images\n",
        "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
        "    \n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                     rotation_range=40,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.05,\n",
        "                                     zoom_range=0.4,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode=\"nearest\")\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=10,\n",
        "                                                      class_mode=\"categorical\",\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=10,\n",
        "                                                                class_mode=\"categorical\",\n",
        "                                                                target_size=(150, 150))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator"
      ],
      "id": "yFNk0wU8UkMB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lokQiTjLUtZG",
        "outputId": "38aecb59-256f-419d-c26e-2fc615d13ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1556 images belonging to 6 classes.\n",
            "Found 177 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ],
      "id": "lokQiTjLUtZG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJseINUFXgB7",
        "outputId": "d6310d4c-b26f-4cd5-b9fa-2f3f3daa2574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-06 13:26:49--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.128, 142.250.153.128, 142.250.145.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  22.2MB/s    in 4.3s    \n",
            "\n",
            "2023-06-06 13:26:53 (19.6 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "id": "SJseINUFXgB7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1Qa5Y9Eacgl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Set the weights file you downloaded into a variable\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "# Initialize the base model.\n",
        "# Set the input shape and remove the dense layers.\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "# Load the pre-trained weights you downloaded.\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Freeze the weights of the layers.\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "id": "X1Qa5Y9Eacgl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXtk_69balpH",
        "outputId": "dfc9ef57-10d0-4913-e85b-5a267343a6fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "pre_trained_model.summary()"
      ],
      "id": "IXtk_69balpH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT36Kkp8a-EN",
        "outputId": "c9318abe-a807-4b4d-92ca-95ba52807c0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ]
        }
      ],
      "source": [
        "# Choose `mixed_7` as the last layer of your base model\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "id": "KT36Kkp8a-EN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsqeFPxuasz_"
      },
      "outputs": [],
      "source": [
        "# ## This cell is for finding the learning_rate\n",
        "\n",
        "# # Flatten the output layer to 1 dimension\n",
        "# x = layers.Flatten()(last_output)\n",
        "# # Add a dropout rate of 0.2\n",
        "# x = layers.Dropout(0.2)(x)     \n",
        "# # Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "# x = layers.Dense(1024, activation='relu')(x)             \n",
        "# # Add a final sigmoid layer for classification\n",
        "# x = layers.Dense(256, activation='relu')(x)             \n",
        "# # Add a final sigmoid layer for classification\n",
        "# x = layers.Dense  (6, activation='softmax')(x)           \n",
        "\n",
        "# # Append the dense network to the base model\n",
        "# model_tune = Model(pre_trained_model.input, x) \n",
        "\n",
        "# # Set the learning rate scheduler\n",
        "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "#     lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "\n",
        "# # Compile the Model to tune the learning rate\n",
        "# model_tune.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "#                 loss='categorical_crossentropy')\n",
        "\n",
        "# # Train the model\n",
        "# history = model_tune.fit(train_generator, epochs=100, verbose=1, callbacks=[lr_schedule])\n",
        "\n",
        "# # Define the learning rate array\n",
        "# lrs = 1e-8 * (10 ** (np.arange(100) / 20))\n",
        "\n",
        "# # Set the figure size\n",
        "# plt.figure(figsize=(10, 6))\n",
        "\n",
        "# # Set the grid\n",
        "# plt.grid(True)\n",
        "\n",
        "# # Plot the loss in log scale\n",
        "# plt.semilogx(lrs, history.history[\"loss\"])\n",
        "\n",
        "# # Increase the tickmarks size\n",
        "# plt.tick_params('both', length=10, width=1, which='both')\n",
        "\n",
        "# # Set the plot boundaries\n",
        "# plt.axis([1e-8, 1e-3, 0, 2])"
      ],
      "id": "TsqeFPxuasz_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4IEL52C4gzS"
      },
      "outputs": [],
      "source": [
        "# for lr in range(len(history.history['lr'])):\n",
        "#   if (history.history['loss'][lr] == min(history.history['loss'])):\n",
        "#     print(history.history['lr'][lr])\n",
        "#     print(history.history['loss'][lr])\n",
        "  "
      ],
      "id": "Z4IEL52C4gzS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEZA4TUHrffB"
      },
      "outputs": [],
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)     \n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)             \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(256, activation='relu')(x)             \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (6, activation='softmax')(x)           \n",
        "\n",
        "# Append the dense network to the base model\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "# Print the model summary. See your dense network connected at the end.\n",
        "# model.summary()"
      ],
      "id": "GEZA4TUHrffB"
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.98):\n",
        "      print(\"\\nReached 98% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "EZMbr5rS4DPt"
      },
      "id": "EZMbr5rS4DPt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYqREEHCbbBz"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "id": "aYqREEHCbbBz"
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "_0FpOHOt4RCo"
      },
      "id": "_0FpOHOt4RCo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHz7u4QQbzQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2cadfec-7940-4a39-b824-ee438a5b87da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "156/156 [==============================] - 77s 406ms/step - loss: 1.1793 - accuracy: 0.5656 - val_loss: 0.3509 - val_accuracy: 0.8983\n",
            "Epoch 2/100\n",
            "156/156 [==============================] - 59s 378ms/step - loss: 0.7406 - accuracy: 0.7449 - val_loss: 0.2304 - val_accuracy: 0.9209\n",
            "Epoch 3/100\n",
            "156/156 [==============================] - 56s 358ms/step - loss: 0.6162 - accuracy: 0.7731 - val_loss: 0.1944 - val_accuracy: 0.9322\n",
            "Epoch 4/100\n",
            "156/156 [==============================] - 56s 361ms/step - loss: 0.5873 - accuracy: 0.7873 - val_loss: 0.1597 - val_accuracy: 0.9322\n",
            "Epoch 5/100\n",
            "156/156 [==============================] - 55s 355ms/step - loss: 0.5293 - accuracy: 0.8091 - val_loss: 0.1453 - val_accuracy: 0.9548\n",
            "Epoch 6/100\n",
            "156/156 [==============================] - 55s 356ms/step - loss: 0.4892 - accuracy: 0.8329 - val_loss: 0.1295 - val_accuracy: 0.9548\n",
            "Epoch 7/100\n",
            "156/156 [==============================] - 55s 356ms/step - loss: 0.4736 - accuracy: 0.8194 - val_loss: 0.1470 - val_accuracy: 0.9435\n",
            "Epoch 8/100\n",
            "156/156 [==============================] - 61s 389ms/step - loss: 0.4372 - accuracy: 0.8438 - val_loss: 0.1469 - val_accuracy: 0.9435\n",
            "Epoch 9/100\n",
            "156/156 [==============================] - 56s 356ms/step - loss: 0.4310 - accuracy: 0.8438 - val_loss: 0.1251 - val_accuracy: 0.9548\n",
            "Epoch 10/100\n",
            "156/156 [==============================] - 56s 360ms/step - loss: 0.4349 - accuracy: 0.8387 - val_loss: 0.1472 - val_accuracy: 0.9322\n",
            "Epoch 11/100\n",
            "156/156 [==============================] - 56s 357ms/step - loss: 0.3677 - accuracy: 0.8683 - val_loss: 0.1240 - val_accuracy: 0.9435\n",
            "Epoch 12/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.3593 - accuracy: 0.8779 - val_loss: 0.1388 - val_accuracy: 0.9435\n",
            "Epoch 13/100\n",
            "156/156 [==============================] - 56s 357ms/step - loss: 0.3637 - accuracy: 0.8753 - val_loss: 0.1627 - val_accuracy: 0.9209\n",
            "Epoch 14/100\n",
            "156/156 [==============================] - 56s 360ms/step - loss: 0.3760 - accuracy: 0.8663 - val_loss: 0.1233 - val_accuracy: 0.9492\n",
            "Epoch 15/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.3432 - accuracy: 0.8837 - val_loss: 0.1408 - val_accuracy: 0.9379\n",
            "Epoch 16/100\n",
            "156/156 [==============================] - 56s 359ms/step - loss: 0.3415 - accuracy: 0.8805 - val_loss: 0.2125 - val_accuracy: 0.9322\n",
            "Epoch 17/100\n",
            "156/156 [==============================] - 56s 361ms/step - loss: 0.3227 - accuracy: 0.8882 - val_loss: 0.1724 - val_accuracy: 0.9435\n",
            "Epoch 18/100\n",
            "156/156 [==============================] - 57s 363ms/step - loss: 0.2953 - accuracy: 0.8978 - val_loss: 0.1325 - val_accuracy: 0.9548\n",
            "Epoch 19/100\n",
            "156/156 [==============================] - 55s 355ms/step - loss: 0.2872 - accuracy: 0.8920 - val_loss: 0.1462 - val_accuracy: 0.9492\n",
            "Epoch 20/100\n",
            "156/156 [==============================] - 59s 380ms/step - loss: 0.3194 - accuracy: 0.8862 - val_loss: 0.2054 - val_accuracy: 0.9153\n",
            "Epoch 21/100\n",
            "156/156 [==============================] - 55s 351ms/step - loss: 0.2936 - accuracy: 0.8882 - val_loss: 0.1312 - val_accuracy: 0.9435\n",
            "Epoch 22/100\n",
            "156/156 [==============================] - 56s 360ms/step - loss: 0.3025 - accuracy: 0.8901 - val_loss: 0.2199 - val_accuracy: 0.9153\n",
            "Epoch 23/100\n",
            "156/156 [==============================] - 57s 363ms/step - loss: 0.2841 - accuracy: 0.8997 - val_loss: 0.1567 - val_accuracy: 0.9435\n",
            "Epoch 24/100\n",
            "156/156 [==============================] - 56s 361ms/step - loss: 0.2768 - accuracy: 0.9042 - val_loss: 0.3038 - val_accuracy: 0.8927\n",
            "Epoch 25/100\n",
            "156/156 [==============================] - 57s 363ms/step - loss: 0.2884 - accuracy: 0.8985 - val_loss: 0.1759 - val_accuracy: 0.9435\n",
            "Epoch 26/100\n",
            "156/156 [==============================] - 57s 366ms/step - loss: 0.2855 - accuracy: 0.8985 - val_loss: 0.2032 - val_accuracy: 0.9322\n",
            "Epoch 27/100\n",
            "156/156 [==============================] - 57s 364ms/step - loss: 0.2501 - accuracy: 0.9100 - val_loss: 0.1937 - val_accuracy: 0.9209\n",
            "Epoch 28/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.2370 - accuracy: 0.9203 - val_loss: 0.2014 - val_accuracy: 0.9209\n",
            "Epoch 29/100\n",
            "156/156 [==============================] - 56s 360ms/step - loss: 0.2641 - accuracy: 0.8991 - val_loss: 0.1512 - val_accuracy: 0.9435\n",
            "Epoch 30/100\n",
            "156/156 [==============================] - 56s 357ms/step - loss: 0.2066 - accuracy: 0.9242 - val_loss: 0.1995 - val_accuracy: 0.9153\n",
            "Epoch 31/100\n",
            "156/156 [==============================] - 56s 358ms/step - loss: 0.2024 - accuracy: 0.9280 - val_loss: 0.1315 - val_accuracy: 0.9548\n",
            "Epoch 32/100\n",
            "156/156 [==============================] - 56s 360ms/step - loss: 0.2758 - accuracy: 0.9004 - val_loss: 0.1521 - val_accuracy: 0.9435\n",
            "Epoch 33/100\n",
            "156/156 [==============================] - 57s 368ms/step - loss: 0.2405 - accuracy: 0.9158 - val_loss: 0.1349 - val_accuracy: 0.9548\n",
            "Epoch 34/100\n",
            "156/156 [==============================] - 57s 368ms/step - loss: 0.2074 - accuracy: 0.9267 - val_loss: 0.1628 - val_accuracy: 0.9492\n",
            "Epoch 35/100\n",
            "156/156 [==============================] - 57s 362ms/step - loss: 0.2082 - accuracy: 0.9293 - val_loss: 0.1671 - val_accuracy: 0.9435\n",
            "Epoch 36/100\n",
            "156/156 [==============================] - 57s 363ms/step - loss: 0.2294 - accuracy: 0.9190 - val_loss: 0.1710 - val_accuracy: 0.9266\n",
            "Epoch 37/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.2327 - accuracy: 0.9190 - val_loss: 0.2039 - val_accuracy: 0.9153\n",
            "Epoch 38/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.2170 - accuracy: 0.9197 - val_loss: 0.1910 - val_accuracy: 0.8983\n",
            "Epoch 39/100\n",
            "156/156 [==============================] - 57s 364ms/step - loss: 0.2397 - accuracy: 0.9126 - val_loss: 0.1486 - val_accuracy: 0.9379\n",
            "Epoch 40/100\n",
            "156/156 [==============================] - 57s 363ms/step - loss: 0.2163 - accuracy: 0.9235 - val_loss: 0.1476 - val_accuracy: 0.9548\n",
            "Epoch 41/100\n",
            "156/156 [==============================] - 56s 361ms/step - loss: 0.1596 - accuracy: 0.9441 - val_loss: 0.1615 - val_accuracy: 0.9322\n",
            "Epoch 42/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.1815 - accuracy: 0.9344 - val_loss: 0.1471 - val_accuracy: 0.9322\n",
            "Epoch 43/100\n",
            "156/156 [==============================] - 56s 359ms/step - loss: 0.2245 - accuracy: 0.9254 - val_loss: 0.1745 - val_accuracy: 0.9322\n",
            "Epoch 44/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.1912 - accuracy: 0.9402 - val_loss: 0.1267 - val_accuracy: 0.9435\n",
            "Epoch 45/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.2055 - accuracy: 0.9280 - val_loss: 0.1479 - val_accuracy: 0.9322\n",
            "Epoch 46/100\n",
            "156/156 [==============================] - 56s 361ms/step - loss: 0.1701 - accuracy: 0.9415 - val_loss: 0.1742 - val_accuracy: 0.9322\n",
            "Epoch 47/100\n",
            "156/156 [==============================] - 56s 360ms/step - loss: 0.1868 - accuracy: 0.9364 - val_loss: 0.1488 - val_accuracy: 0.9379\n",
            "Epoch 48/100\n",
            "156/156 [==============================] - 56s 356ms/step - loss: 0.2042 - accuracy: 0.9299 - val_loss: 0.1592 - val_accuracy: 0.9322\n",
            "Epoch 49/100\n",
            "156/156 [==============================] - 56s 358ms/step - loss: 0.1660 - accuracy: 0.9428 - val_loss: 0.1838 - val_accuracy: 0.9209\n",
            "Epoch 50/100\n",
            "156/156 [==============================] - 56s 358ms/step - loss: 0.1547 - accuracy: 0.9479 - val_loss: 0.2168 - val_accuracy: 0.9209\n",
            "Epoch 51/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.1645 - accuracy: 0.9447 - val_loss: 0.1870 - val_accuracy: 0.9379\n",
            "Epoch 52/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.1427 - accuracy: 0.9518 - val_loss: 0.1934 - val_accuracy: 0.9209\n",
            "Epoch 53/100\n",
            "156/156 [==============================] - 56s 361ms/step - loss: 0.1513 - accuracy: 0.9454 - val_loss: 0.2292 - val_accuracy: 0.9153\n",
            "Epoch 54/100\n",
            "156/156 [==============================] - 57s 364ms/step - loss: 0.1814 - accuracy: 0.9351 - val_loss: 0.1902 - val_accuracy: 0.9209\n",
            "Epoch 55/100\n",
            "156/156 [==============================] - 58s 372ms/step - loss: 0.1877 - accuracy: 0.9306 - val_loss: 0.1563 - val_accuracy: 0.9435\n",
            "Epoch 56/100\n",
            "156/156 [==============================] - 57s 365ms/step - loss: 0.1612 - accuracy: 0.9454 - val_loss: 0.1745 - val_accuracy: 0.9435\n",
            "Epoch 57/100\n",
            "156/156 [==============================] - 58s 371ms/step - loss: 0.1913 - accuracy: 0.9299 - val_loss: 0.1563 - val_accuracy: 0.9379\n",
            "Epoch 58/100\n",
            "156/156 [==============================] - 57s 364ms/step - loss: 0.1714 - accuracy: 0.9389 - val_loss: 0.1757 - val_accuracy: 0.9153\n",
            "Epoch 59/100\n",
            "156/156 [==============================] - 56s 359ms/step - loss: 0.1649 - accuracy: 0.9422 - val_loss: 0.1875 - val_accuracy: 0.9209\n",
            "Epoch 60/100\n",
            "156/156 [==============================] - 55s 356ms/step - loss: 0.1393 - accuracy: 0.9524 - val_loss: 0.2649 - val_accuracy: 0.9209\n",
            "Epoch 61/100\n",
            "156/156 [==============================] - 57s 362ms/step - loss: 0.1590 - accuracy: 0.9473 - val_loss: 0.1784 - val_accuracy: 0.9379\n",
            "Epoch 62/100\n",
            "156/156 [==============================] - 56s 359ms/step - loss: 0.1327 - accuracy: 0.9524 - val_loss: 0.1481 - val_accuracy: 0.9435\n",
            "Epoch 63/100\n",
            "156/156 [==============================] - 56s 361ms/step - loss: 0.1503 - accuracy: 0.9454 - val_loss: 0.2381 - val_accuracy: 0.9153\n",
            "Epoch 64/100\n",
            "156/156 [==============================] - 56s 362ms/step - loss: 0.1547 - accuracy: 0.9492 - val_loss: 0.2089 - val_accuracy: 0.9266\n",
            "Epoch 65/100\n",
            "156/156 [==============================] - 56s 359ms/step - loss: 0.1556 - accuracy: 0.9518 - val_loss: 0.1971 - val_accuracy: 0.9322\n",
            "Epoch 66/100\n",
            "156/156 [==============================] - 57s 364ms/step - loss: 0.1583 - accuracy: 0.9486 - val_loss: 0.1761 - val_accuracy: 0.9435\n",
            "Epoch 67/100\n",
            "156/156 [==============================] - 57s 367ms/step - loss: 0.1745 - accuracy: 0.9441 - val_loss: 0.2062 - val_accuracy: 0.9266\n",
            "Epoch 68/100\n",
            "156/156 [==============================] - 57s 367ms/step - loss: 0.1133 - accuracy: 0.9627 - val_loss: 0.1967 - val_accuracy: 0.9266\n",
            "Epoch 69/100\n",
            "156/156 [==============================] - 57s 368ms/step - loss: 0.1419 - accuracy: 0.9499 - val_loss: 0.2116 - val_accuracy: 0.9266\n",
            "Epoch 70/100\n",
            "156/156 [==============================] - 57s 363ms/step - loss: 0.1594 - accuracy: 0.9460 - val_loss: 0.1837 - val_accuracy: 0.9322\n",
            "Epoch 71/100\n",
            "156/156 [==============================] - 57s 364ms/step - loss: 0.1368 - accuracy: 0.9550 - val_loss: 0.2376 - val_accuracy: 0.9209\n",
            "Epoch 72/100\n",
            "156/156 [==============================] - 57s 365ms/step - loss: 0.1334 - accuracy: 0.9512 - val_loss: 0.2260 - val_accuracy: 0.9435\n",
            "Epoch 73/100\n",
            "156/156 [==============================] - 58s 370ms/step - loss: 0.1208 - accuracy: 0.9569 - val_loss: 0.1869 - val_accuracy: 0.9492\n",
            "Epoch 74/100\n",
            "156/156 [==============================] - 58s 370ms/step - loss: 0.1448 - accuracy: 0.9499 - val_loss: 0.2020 - val_accuracy: 0.9548\n",
            "Epoch 75/100\n",
            "156/156 [==============================] - 57s 364ms/step - loss: 0.1252 - accuracy: 0.9589 - val_loss: 0.2247 - val_accuracy: 0.9379\n",
            "Epoch 76/100\n",
            "156/156 [==============================] - 57s 367ms/step - loss: 0.1353 - accuracy: 0.9595 - val_loss: 0.2318 - val_accuracy: 0.9266\n",
            "Epoch 77/100\n",
            "156/156 [==============================] - 57s 368ms/step - loss: 0.1357 - accuracy: 0.9486 - val_loss: 0.2092 - val_accuracy: 0.9209\n",
            "Epoch 78/100\n",
            "156/156 [==============================] - 56s 358ms/step - loss: 0.1440 - accuracy: 0.9544 - val_loss: 0.2160 - val_accuracy: 0.9266\n",
            "Epoch 79/100\n",
            "156/156 [==============================] - 56s 355ms/step - loss: 0.1352 - accuracy: 0.9486 - val_loss: 0.2334 - val_accuracy: 0.9266\n",
            "Epoch 80/100\n",
            "156/156 [==============================] - 60s 382ms/step - loss: 0.0984 - accuracy: 0.9659 - val_loss: 0.2497 - val_accuracy: 0.9379\n",
            "Epoch 81/100\n",
            "156/156 [==============================] - 56s 359ms/step - loss: 0.1155 - accuracy: 0.9647 - val_loss: 0.2741 - val_accuracy: 0.9266\n",
            "Epoch 82/100\n",
            "156/156 [==============================] - 56s 350ms/step - loss: 0.1117 - accuracy: 0.9557 - val_loss: 0.2797 - val_accuracy: 0.9209\n",
            "Epoch 83/100\n",
            "156/156 [==============================] - 56s 358ms/step - loss: 0.1262 - accuracy: 0.9582 - val_loss: 0.2606 - val_accuracy: 0.9379\n",
            "Epoch 84/100\n",
            "156/156 [==============================] - 55s 356ms/step - loss: 0.1110 - accuracy: 0.9595 - val_loss: 0.3423 - val_accuracy: 0.9209\n",
            "Epoch 85/100\n",
            "156/156 [==============================] - 55s 354ms/step - loss: 0.1193 - accuracy: 0.9602 - val_loss: 0.2322 - val_accuracy: 0.9266\n",
            "Epoch 86/100\n",
            "156/156 [==============================] - 55s 355ms/step - loss: 0.1100 - accuracy: 0.9614 - val_loss: 0.2181 - val_accuracy: 0.9322\n",
            "Epoch 87/100\n",
            "156/156 [==============================] - 56s 357ms/step - loss: 0.0943 - accuracy: 0.9704 - val_loss: 0.2760 - val_accuracy: 0.9322\n",
            "Epoch 88/100\n",
            "156/156 [==============================] - 55s 356ms/step - loss: 0.1320 - accuracy: 0.9524 - val_loss: 0.2311 - val_accuracy: 0.9322\n",
            "Epoch 89/100\n",
            "156/156 [==============================] - 56s 361ms/step - loss: 0.1020 - accuracy: 0.9653 - val_loss: 0.1981 - val_accuracy: 0.9492\n",
            "Epoch 90/100\n",
            "156/156 [==============================] - 56s 360ms/step - loss: 0.1163 - accuracy: 0.9582 - val_loss: 0.2688 - val_accuracy: 0.9153\n",
            "Epoch 91/100\n",
            "156/156 [==============================] - 56s 358ms/step - loss: 0.1156 - accuracy: 0.9589 - val_loss: 0.2063 - val_accuracy: 0.9322\n",
            "Epoch 92/100\n",
            "156/156 [==============================] - 55s 355ms/step - loss: 0.1252 - accuracy: 0.9595 - val_loss: 0.2680 - val_accuracy: 0.9209\n",
            "Epoch 93/100\n",
            "156/156 [==============================] - 60s 382ms/step - loss: 0.1118 - accuracy: 0.9659 - val_loss: 0.2322 - val_accuracy: 0.9322\n",
            "Epoch 94/100\n",
            "156/156 [==============================] - 55s 352ms/step - loss: 0.0971 - accuracy: 0.9627 - val_loss: 0.2436 - val_accuracy: 0.9379\n",
            "Epoch 95/100\n",
            "156/156 [==============================] - 55s 354ms/step - loss: 0.1083 - accuracy: 0.9608 - val_loss: 0.2061 - val_accuracy: 0.9322\n",
            "Epoch 96/100\n",
            "156/156 [==============================] - 55s 355ms/step - loss: 0.1270 - accuracy: 0.9589 - val_loss: 0.2263 - val_accuracy: 0.9435\n",
            "Epoch 97/100\n",
            "156/156 [==============================] - 60s 386ms/step - loss: 0.0928 - accuracy: 0.9698 - val_loss: 0.2187 - val_accuracy: 0.9492\n",
            "Epoch 98/100\n",
            "156/156 [==============================] - 55s 356ms/step - loss: 0.0997 - accuracy: 0.9634 - val_loss: 0.2340 - val_accuracy: 0.9435\n",
            "Epoch 99/100\n",
            "156/156 [==============================] - 55s 355ms/step - loss: 0.0887 - accuracy: 0.9711 - val_loss: 0.2434 - val_accuracy: 0.9435\n",
            "Epoch 100/100\n",
            "156/156 [==============================] - 56s 356ms/step - loss: 0.1073 - accuracy: 0.9614 - val_loss: 0.1882 - val_accuracy: 0.9605\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=validation_generator)"
      ],
      "id": "JHz7u4QQbzQx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMCwavREXtLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "26096911-5344-4714-c5bf-18112d671327"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.show()"
      ],
      "id": "hMCwavREXtLF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDSxzBb72j86"
      },
      "outputs": [],
      "source": [],
      "id": "jDSxzBb72j86"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d1a6480"
      },
      "source": [
        "**Congratulations**"
      ],
      "id": "9d1a6480"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEc0gn7I3HUt"
      },
      "source": [
        "## Save model "
      ],
      "id": "rEc0gn7I3HUt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPck707w3LNd"
      },
      "outputs": [],
      "source": [
        "# UNCOMMENT TO RUN THE THINGY"
      ],
      "id": "SPck707w3LNd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG33gCXk3PY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a7879dc-ba57-4d9e-856c-14d89d94d341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 70). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model_path = \"/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/model_transfer_learning.h5\"\n",
        "tf.saved_model.save(model, model_path)"
      ],
      "id": "hG33gCXk3PY6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import model and do prediction (ONLY NEED TO RUN THIS TO PREDICT) "
      ],
      "metadata": {
        "id": "Lb0cc3MN2FrE"
      },
      "id": "Lb0cc3MN2FrE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import model with the h5 format\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# CHANGE the model_path\n",
        "model_path = \"/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/model_transfer_learning.h5\"\n",
        "modelx = tf.saved_model.load(model_path)"
      ],
      "metadata": {
        "id": "zU2PJej_QVN6"
      },
      "id": "zU2PJej_QVN6",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Importing image yang akan di prediksi\n",
        "# Path imagenya bisa di sesuain\n",
        "img = image.load_img('/content/drive/MyDrive/Capstone Bangkit C23-PS142/DATASET ML/DATA APA AJAH/'+'MONAS3.png', target_size=(150,150))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "x = x /255."
      ],
      "metadata": {
        "id": "pqxLf8-gQ_mr"
      },
      "id": "pqxLf8-gQ_mr",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan prediksi\n",
        "prediction = modelx(x)"
      ],
      "metadata": {
        "id": "qla_CrMLQth9"
      },
      "id": "qla_CrMLQth9",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output prediksi\n",
        "class_labels = ['ampera','gadang','gwk','kotatua','monas','ulundanu']\n",
        "label = class_labels[np.argmax(prediction)]\n",
        "print(f\"Prediksi: {label} \\ndengan tingkat Probabilitas: {np.max(prediction)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8xm88gnSecU",
        "outputId": "dc9d9f85-8d42-427b-9c77-d1c97a3810a1"
      },
      "id": "H8xm88gnSecU",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediksi: monas \n",
            "dengan tingkat Probabilitas: 0.9535914063453674\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}